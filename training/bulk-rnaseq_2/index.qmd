---
title: "Introduction to RNA-Seq - Part 2"
author: Mark Dunning
date: 2025-10-25
theme: darkly
image: "/files/training/bulk_rnaseq/TGF_Vs_CTR_volcano.png"
---

# Overview

Performing differential expression on Bulk RNA-seq data using DESeq2

## Quick Start

This section follows on from [Part 1](/training/bulk-rnaseq_part1/index.html) where we saw how to import raw RNA-seq counts into `DESeq2` and perform some quality assessment. Several packages are required, which can be downloaded with this code:-

```{r eval=FALSE}
source("https://raw.githubusercontent.com/markdunning/markdunning.github.com/refs/heads/master/files/training/bulk_rnaseq/install_bioc_packages.R")
```

The following will also assume you have created a `DESeq2` object in a folder called `Robjects` in your working directory. This can be downloaded with the following.

```{r eval=FALSE}
dir.create("Robjects/",showWarnings = FALSE)
download.file("https://github.com/markdunning/markdunning.github.com/raw/refs/heads/master/files/training/bulk_rnaseq/dds.rds",destfile = "Robjects/dds.rds")
```

# Differential expression with `DESeq2`

Now that we are happy that the data quality looks good, we can proceed to test for differentially expressed genes. There are a number of packages to analyse RNA-Seq data. Most people use `DESeq2`, `edgeR` or `limma`. We will use `DESeq2` for the rest of this practical.

## Recap of pre-processing

The previous section walked-through the pre-processing and transformation of the count data. Here, for completeness, we list the minimal steps required to process the data prior to differential expression analysis.

Note that although we spent some time looking at the quality of our data , these steps are not strictly *necessary* prior to performing differential expression so are not shown here for the sake of brevity. Remember, `DESeq2` [requires raw counts](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#why-un-normalized-counts) so the `vst` transformation is not shown as part of this basic protocol.

```{r eval=FALSE}
library(DESeq2)

count_file <- "raw_counts/raw_counts_matrix.tsv"
counts <- read.delim(count_file)

## Step needed for this data to tidy the column names
colnames(counts)[-1] <- stringr::str_remove_all(colnames(counts)[-1], "X")

sampleinfo_corrected <- read.delim("meta_data/sampleInfo_corrected.txt")
dds <- DESeqDataSetFromMatrix(counts, 
                                colData = sampleinfo_corrected,
                                design = ~condition, tidy=TRUE)

saveRDS(dds, file="Robjects/dds.rds")
```

We will be using these raw counts throughout the workshop and transforming them using methods in the `DESeq2` package. If you want to know about alternative methods for count normalisation they are covered on [this page](https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html).

# The DESeq workflow in brief

```{r echo=FALSE, message=FALSE}
library(DESeq2)
dds <- readRDS("Robjects/dds.rds")
```

We have previously defined the `condition` as our factor of interest using the `design` argument when we created the object. This can be checked using the `design` function. The current design can be queried using the `design` function.

```{r}
design(dds)
```

It can be changed at any point before we run the differential expression workflow, can refer to any of the variables saved in the `colData` of the `dds` object, or even a combination of different variables.

```{r}
colData(dds)
```

The counts that we have obtained via sequencing are subject to random sources of variation. The purpose of differential expression is to determine if potential sources of biological variation (e.g. counts observed from different sample groups) are greater than random noise.

The `DESeq` function is the main workflow for differential expression and runs a couple of processing steps automatically to adjust for different library size and gene-wise variability. You can you can read about these in the [DESeq2 vignette](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#the-deseq2-model) and run some example code at the [end of this session](#full-deseq-workflow).

```{r}
de_condition <- DESeq(dds)
de_condition
```

The results of the analysis are not immediately accessible, but can be obtained using the `results` function.

```{r}
results(de_condition)
```

Each row is a particular gene measured in the study (i.e. all genes in the organism being studied) and each column reports some aspect of the differential expression analysis for that gene. The values that I typically pay most attention to are highlighted in **bold**.

| Column Name | Description | Importance |
|----------------------|----------------------------|----------------------|
| **baseMean** | The average of normalized count values (size-factor corrected) across all samples in the comparison. | Measures the average expression magnitude of the gene and useful for basic filtering |
| **log2FoldChange** | The estimated log base 2 fold change between the two groups being contrasted (e.g., Treatment / Control). | The primary measure of the effect size or magnitude of the difference. |
| lfcSE | The standard error estimate for the $\text{log}_2\text{FoldChange}$. | Measures the precision of the $\text{log}_2\text{FC}$ estimate. Smaller values indicate higher reliability. |
| stat | The Wald test statistic (calculated as $\text{log}_2\text{FC} / \text{lfcSE}$) | The statistical value used to test the null hypothesis (that the $\text{log}_2\text{FC}$ is zero) |
| pvalue | The $p$-value derived from the Wald test statistic. | The unadjusted probability of observing the effect by chance. Do not use this for filtering. |
| **padj** | The Benjamini-Hochberg adjusted $p$-value (False Discovery Rate, FDR).CRITICAL for significance. This corrects for multiple testing | CRITICAL for statistical significance. This corrects for multiple testing. Genes are considered differentially expressed if this value is below your threshold (e.g., 0.05). |

Note that **all genes** are reported. At this stage the gene identifiers are not very informative, something we will [fix shortly](#adding-annotation-to-the-deseq2-results). Furthermore, the `results` function displays results in a format which is not compatible with standard data manipulation tools (i.e. `tidyverse`), so we will have to convert.

# Processing the DE results using tidyverse

The output can be converted into a data frame and manipulated in the usual manner if we add the `tidy = TRUE` argument to `results`. It is recommended to use `dplyr` to manipulate the data frames with the standard set of operations detailed on the [dplyr cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

-   `select` to pick which columns to display
-   `filter` to restrict the rows
-   `mutate` to add new variables to the data frame
-   `arrange` to order the data frame according to values of a column or columns


:::{.callout-note}

# A tidy framework for RNA-seq

There is actually a dedicated workflow for those familiar with "tidy" methodologies and wish to apply the same philosophy to RNA-seq and other 'omics data. I plan to cover this at a later point.

- [the tidybulk page](https://github.com/tidyomics/tidybulk)

Neither the `tidybulk` or approach I present here is necessarily better than the other, and should in fact yield exactly the same results.

:::

```{r warning=FALSE, message=FALSE}
library(dplyr)
 results(de_condition, tidy=TRUE) %>% 
   slice_head(n=10)
```

::: callout-note
Although, the "tidy" output is more useful for downstream analysis, I personally like the output generated by the `results` function without `tidy=TRUE` as it displays the contrast being tested (in this case `TGF vs CTR`). This is a good way of checking that you are comparing the groups that you expect.
:::

We can sort the rows by adjusted p-value and then print the first 10 rows. I'm using `slice_head` function as a `dplyr` equivalent to the base `head`.

```{r}
results(de_condition,tidy=TRUE) %>%
  arrange(padj) %>%  
  slice_head(n=10)
```

Or we can sort the rows and then write the resulting data frame to a file. 

:::{.callout-note}

# File naming 

You can name the csv as anything - although something like `results.csv` is probably not particularly helpful for all but the simplest datasets. Personally, I like to choose file names that are informative about the contents even if they do look a bit complicated.

:::

```{r}
dir.create("de_analysis",showWarnings = FALSE)
 results(de_condition,tidy=TRUE) %>%
  arrange(padj) %>% 
   readr::write_csv("de_analysis/condition_TGF_vs_CTR_DESeq_all.csv")
```

Filtering to the differentially-expressed genes can be achieved using the `filter` function from `dplyr` with some cut-off on the adjusted p-value.

```{r}
 results(de_condition,tidy=TRUE) %>%
  filter(padj < 0.05) %>% 
  readr::write_csv("de_analysis/condition_TGF_vs_CTR_DESeq_sig.csv")
```

It is also a good idea to save the DESeq output object itself so we can re-use later.

```{r}
saveRDS(de_condition, file="Robjects/de_condition.rds")
```

We can discover how many differentially-expressed genes (at a particular p-value cut-off) using the `count` function. I am making sure that I explicitly use the `count` function from `dplyr` using the technique of putting `dplyr::` before `count`.

```{r}
results(de_condition,tidy=TRUE) %>%
  dplyr::count(padj < 0.05)
```

:::{.callout-note}

You may notice the amount of `NA` p-values here. We will come back to this later, but it is related to some filtering that `DESeq2` is doing as default.

:::

Another overview of the results is to use the `plotMA` function. Each point on this plot represents and individual gene with the x- and y-axes being the overall expression level and magnitude of difference respectively. Statistically significant genes are automatically highlighted. The fanning effect at low expression levels is often seen due to high relative fold-change at low expression levels. Once you have run your DE analysis, an MA plot visually confirms that your DE genes are not exclusively confined to extremely low-count regions.

```{r}
plotMA(de_condition)
```

It is also instructive to perform a "sanity" check and plot the sample-level counts for genes with high significance. This could highlight any other technical factors that we are not currently taking into account. The plot is not particularly attractive, but is a good quick diagnostic as it confirms which direction your contrast is. i.e. Treatment vs Control or Control vs Treatment.

```{r}
## Get the gene lowest p-value and a log2 fold-change over 0

top_up <- results(de_condition, tidy = TRUE) %>% 
  filter(log2FoldChange > 0) %>% 
  slice_min(padj) %>% 
  pull(row)
plotCounts(dds,top_up,intgroup = "condition")
```

```{r}

## Get the gene with the lowest p-value and a log2 fold-change less than 0
top_down <- results(de_condition, tidy = TRUE) %>% 
  filter(log2FoldChange < 0) %>% 
  slice_min(padj) %>% 
  pull(row)

plotCounts(dds,top_down,intgroup = "condition")
```

::: callout-note
If your study involves knocking-out a particular gene, or you have some positive controls that are known in advance, it would be a good idea to visualise their expression level with `plotCounts`.
:::

# Changing the direction of the contrast, or the groups being compared

You hopefully noticed that the sign of the log fold changes have been calculated using the `CTR` group as a baseline. In other words, a positive `log2FoldChange` means that a gene has higher expression in `TGF` compared to `CTR`. This is usually the direction that makes sense for biological interpretation. However, `DESeq2` has not done anything clever here. The order of the contrasts is dictated by the "levels" of the variable used in the design.

```{r}
dds$condition
```

Since `CTR` is the first thing printed here it gets chosen as the baseline. It is just a fortunate coincidence that `CTR` is first alphabetically! In order that we are not relying on the defaults and for transparency, I tend to explicitly state which contrast I want to make using the `contrast` argument and have full control over what the baseline is. In the `contrast` argument you create a vector (using `c`) followed by the levels in the order you want to compare with the baseline coming last.

In the below this can be read as `TGF` vs `CTR`, which is in fact the default

```{r}
## This should give the same as the table above
results(de_condition, contrast=c("condition","TGF","CTR"))

```

IF we wanted to change the order we can do:-

```{r eval=FALSE}
## Changing the direction of the contrast
results(de_condition, contrast=c("condition","CTR","TGF"))
```

::: callout-important
# Use the DESeq function once and once only!
:::


You might be wondering why, if I am comparing `CTR` to `TGF` samples, do I have the `IR` samples in my dataset? I have seen people doing an analysis like this on just the `CTR` and `TGF` samples, and create another `DESeqDataset` object to compare `CTR` to `IR`. Unfortunately, this is not the recommended best practice.

When you call `DESeq(dds)`, the function performs several crucial steps:

- Size Factor Estimation: It calculates the normalization factors based on all samples simultaneously.
- Dispersion Estimation: Crucially, it estimates the gene-wise and final dispersion (variance) parameters across all samples. 

By using all samples together, the model gets a much more robust and accurate estimate of the gene-specific variance. This is especially important for groups with small sample sizes (e.g., $n=3$ or $n=4$). 

Pooling information across the entire experiment makes the statistical test for any individual comparison more powerful and reliable. Furthermore, Running `DESeq()` takes time, as it involves fitting thousands of generalized linear models and optimizing dispersion estimates. If you were to subset your data and run `DESeq()` separately for every comparison (e.g., once for `TGF` vs `CTR`, then again for `IR` vs `CTR`), you would be wasting computational time and diminishing the statistical power of the analysis.

You should perform the full differential expression analysis by calling `DESeq(dds)` only once on your combined dataset. Then, you use the `results()` function multiple times to extract the specific pairwise comparisons or complex contrasts you are interested in.

## Exercise

-   Re-run the analysis to find differentially-expressed genes between the `IR` treated samples and `CTR`
-   Write a csv file that contains results for the genes that have an *adjusted* p-value less than 0.05 and a log2 fold change more than 1, or less than -1 in the contrast of TGF vs CTRL.
-   Use the `plotCounts` function to visually-inspect the most statistically-significant gene identified


:::{.callout-note collapse="true"}

```{r}
## Like to run the `results` function without `tidy=TRUE` to check everything is working
results(de_condition, contrast = c("condition", "IR", "CTR"))

results(de_condition, contrast = c("condition", "IR", "CTR"), tidy = TRUE) %>% 
  arrange(padj) %>% 
  filter(padj < 0.05, abs(log2FoldChange) > 1) %>% 
  readr::write_csv("de_analysis/condition_IR_vs_CTR_sig_genes.csv")


```


:::

# More complex designs

The examples we have used so far have performed a differential expression analysis using a named column in the `colData` object. The `DESeq2` package is capable of performing more complex analyses that can take multiple factors into consideration at the same time; so-called "multi-factor designs"

-   [Multi-factor designs in DESeq2](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#multi-factor-designs)

The use of such a design could be motivated by discovering sources of technical variation in our data that might obscure the biological differences we would like to compare. e.g.

![](/files/training/bulk_rnaseq/batch_effect.png)

In the example image above the main source of variation is the batch in which the samples were sequenced. A multi-factor analysis to compare the various conditions, but "correct" for differences in batch, would be as follows.

```{r eval=FALSE}
### Don't run this. It's just a code example
design(MY_DATA) <- ~ batch + condition
```

Likewise, if we have different treatments applied to difference cell-lines, but the main source of variation is the cell line the following could be used.

```{r eval=FALSE}
### Don't run this. It's just a code example
design(MY_DATA) <- ~cell_line + treatment
```

# Adding annotation to the DESeq2 results {#adding-annotation-to-the-deseq2-results}

We would love to share these results with our collaborators, or search for our favourite gene in the results. However, the results are not very useful in there current form as each row is named according to an *Ensembl* identifier. Whilst gene symbols are problematic and can change over time, they are the names that are most recognisable and make the results easier to navigate.

There are a number of ways to add annotation, but we will demonstrate how to do this using the *org.Hs.eg.db* package. This package is one of several *organism-level* packages in Bioconductor that are re-built every 6 months. These packages are listed on the [annotation section](http://bioconductor.org/packages/release/BiocViews.html#___AnnotationData) of the Bioconductor, and are installed in the same way as regular Bioconductor packages. An alternative approach is to use `biomaRt`, an interface to the [BioMart](http://www.biomart.org/) resource. BioMart is much more comprehensive, but the organism packages do not require online access once downloaded.

```{r eval=FALSE}
### Only execute when you need to install the package
install.packages("BiocManager")
BiocManager::install("org.Hs.eg.db")
# For Mouse
BiocManager::install("org.Mm.eg.db")
```

The packages are larger in size that Bioconductor software packages, but essentially they are databases that can be used to make *offline* queries. An alternatve (`biomaRt`) that connects to the ensembl [biomart](https://www.ensembl.org/info/data/biomart/index.html) resource will be discussed later.

```{r message=FALSE}
library(org.Hs.eg.db)
```

First we need to decide what information we want. In order to see what we can extract we can run the `columns` function on the annotation database.

```{r}
columns(org.Hs.eg.db)
```

We are going to filter the database by a key or set of keys in order to extract the information we want. Valid names for the key can be retrieved with the `keytypes` function.

```{r}
keytypes(org.Hs.eg.db)
```

We should see `ENSEMBL`, which is the type of key we are going to use in this case. If we are unsure what values are acceptable for the key, we can check what keys are valid with `keys`

```{r}
keys(org.Hs.eg.db, keytype="ENSEMBL")[1:10]
```

For the top gene in our analysis the call to the function would be:-

```{r eval=FALSE}
select(org.Hs.eg.db, keys=top_up,
       keytype = "ENSEMBL",columns=c("SYMBOL","GENENAME")
)
```

Unfortunately, the authors of `dplyr` and `AnnotationDbi` have both decided to use the name `select` in their packages. To avoid confusion and errors, the following code is sometimes used:-

```{r}
AnnotationDbi::select(org.Hs.eg.db, keys=top_up,keytype = "ENSEMBL",columns=c("SYMBOL","GENENAME"))
```

To annotate our results, we definitely want gene symbols and perhaps the full gene name. Let's build up our annotation information into a new data frame using the `select` function.

```{r}
anno <- AnnotationDbi::select(org.Hs.eg.db,keys=rownames(dds),
              columns=c("SYMBOL","GENENAME"),
              keytype="ENSEMBL")
# Have a look at the annotation
head(anno)
```

However, we have a problem that the resulting data frame has more rows than our results table. This is due to the *one-to-many* relationships that often occur when mapping between various identifiers.

```{r}
dim(anno)
dim(dds)
```

Such duplicated entries can be identified using the `duplicated` function. Fortunately, there are not too many so hopefully we won't lose too much information if we discard the entries that are duplicated. The first occurrence of the duplicated ID will still be included in the table.

```{r}
anno <- AnnotationDbi::select(org.Hs.eg.db,keys=rownames(dds),
            columns=c("ENSEMBL","SYMBOL","GENENAME","ENTREZID"),
            keytype="ENSEMBL") %>% 
filter(!duplicated(ENSEMBL))
dim(anno)
```

We can bind in the annotation information to the `results` data frame.

```{r}
results_annotated <- results(de_condition,tidy=TRUE) %>% 
  left_join(anno, by=c("row"="ENSEMBL"))

head(results_annotated)
```

We can save the results table using the `write.csv` function, which writes the results out to a csv file that you can open in excel.

```{r}
write.csv(results_annotated,file="de_analysis/condition_TGF_vs_CTR_DESeq_annotated.csv",row.names=FALSE)
```

## Exercise

-   The publication gives examples of `COL1A1`, `COL1A2` and `COL3A1` as genes that are *up-regulated* in TGF-treated samples vs controls (Figure 6C). Use your data to verify this by
    i)  extracting their p-values
    ii) plotting the counts for these genes

:::{.callout-note collapse="true"}


# Solution

We already have the differential expression statistics for the contrast `TGF` vs `CTR` and have just added gene names (`SYMBOL`) into the `results_annotated`. We can therefore filter our results to rows that match any of these genes of interest.

```{r}

genes_of_interest <- c("COL1A1", "COL1A2", "COL3A1")

## To make the output a bit cleaner I will select a few columns of interest. 
filter(results_annotated, SYMBOL %in% genes_of_interest) %>% 
  dplyr::select(log2FoldChange, padj, SYMBOL)


```

Indeed they all are significant with a positive fold-change indicating higher expression in `TGF`-treated samples. Plotting the counts for genes requires a bit more thought, as the following does not work as we might hope


```{r eval=FALSE}
plotCounts(dds, "COL1A1", intgroup = "condition")
```

<pre>

`Error in counts(dds, normalized = normalized, replaced = replaced)[gene,  : 
  subscript out of bounds`
</pre>

The error is not particularly helpful, but it basically means that it cannot find counts for `COL1A1` in the `dds` object. Although we have added gene names to the analysis, they only appear in our results table and the gene counts are still referred to by ensembl IDS.

```{r}
ens_ids <- filter(results_annotated, SYMBOL %in% genes_of_interest) %>% 
  pull(row)

ens_ids

```
This code works, but is a bit clunky. N.B. `par(mfrow=c(1,3))` is the base R plotting way of making a panel with one row and three columns

```{r}
par(mfrow=c(1,3))

plotCounts(dds, ens_ids[1], intgroup = "condition")
plotCounts(dds, ens_ids[2], intgroup = "condition")
plotCounts(dds, ens_ids[3], intgroup = "condition")

```

To do a nicer job we can use `ggplot2` after some data manipulation. The first step is to get normalized counts for all genes after explicitly using the `estimateSizeFactors`. We don't normally need to use this function as it is part of the `DESeq` workflow. 

The results is a data frame with ensembl IDs in the rows.

```{r}
dds <- estimateSizeFactors(dds)
norm_counts <- counts(dds, normalized = TRUE)
head(norm_counts)
```
We can filter these counts by the ensembl IDs we identified for these genes; provided that the ensembl ID appears as a column name. 
```{r}
norm_counts %>% 
  data.frame() %>% 
  tibble:::rownames_to_column("row") %>% 
  filter(row %in% ens_ids)

```

However, these are not in the tidy form that `ggplot2` requires so we have to reshape the data using `tidyr`'s `pivot_longer` function. Turning the counts into a data frame introduced an "X" at the start of the column names, so we better remove that.

```{r}

norm_counts %>% 
  data.frame() %>% 
  tibble:::rownames_to_column("row") %>% 
  filter(row %in% ens_ids) %>% 
  tidyr::pivot_longer(-row, names_to = "Run", values_to = "count") %>% 
  mutate(Run = stringr::str_remove_all(Run, "X"))

```

Now we have the counts in a tidy form, but we don't know the sample groupings. The groupings can be obtained from the `colData` 

```{r}

sampleInfo <- colData(dds) %>% data.frame

norm_counts %>% 
  data.frame() %>% 
  tibble:::rownames_to_column("row") %>% 
  filter(row %in% ens_ids) %>% 
  tidyr::pivot_longer(-row, names_to = "Run", values_to = "count") %>% 
  mutate(Run = stringr::str_remove_all(Run, "X")) %>% 
  left_join(sampleInfo, by = "Run")


```


Finally, we can make the plot of count against condition

```{r}
library(ggplot2)
norm_counts %>% 
  data.frame() %>% 
  tibble:::rownames_to_column("row") %>% 
  filter(row %in% ens_ids) %>% 
  tidyr::pivot_longer(-row, names_to = "Run", values_to = "count") %>% 
  mutate(Run = stringr::str_remove_all(Run, "X")) %>% 
  left_join(sampleInfo, by = "Run") %>% 
  ggplot(aes(x = condition, y = count, col = condition)) + geom_jitter(width=0.1) + facet_wrap(~row)
```
But what are the most recognisable names for these genes? We could use the `results_annotated` table that we already made and we could then `facet` using the `SYMBOL` which will print the gene names automatically.

```{r}
norm_counts %>% 
  data.frame() %>% 
  tibble:::rownames_to_column("row") %>% 
  filter(row %in% ens_ids) %>% 
  tidyr::pivot_longer(-row, names_to = "Run", values_to = "count") %>% 
  mutate(Run = stringr::str_remove_all(Run, "X")) %>% 
  left_join(sampleInfo, by = "Run") %>% 
  left_join(results_annotated, by = "row") %>% 
  ggplot(aes(x = condition, y = count, col = condition)) + geom_jitter(width=0.1) + facet_wrap(~SYMBOL)

```

Admittedly, that *was* quite a bit of effort and would have been simpler with a `tidybulk` approach from the start. If you were interested in lots of gene sets like `genes_of_interest` then it would we worth making the code into a function that could be run without having to repeat the code all the time.


:::


# Heatmaps

You may have already seen the use of a heatmap as a quality assessment tool to visualise the relationship between samples in an experiment. Another common use-case for such a plot is to visualise the results of a differential expression analysis. Although `ggplot2` has a `geom_tile` function to make heatmaps, specialised packages such as `pheatmaps` offer more functionality such as clustering the samples.

The counts we are visualising are the *variance-stablised* counts, which are more appropriate for visualisation.

Here we will take the top 10 genes from the differential expression analysis and produce a heatmap with the `pheatmap` package. We can take advantage of the fact the our counts table contains Ensembl gene names in the rows. Standard subset operations in R can then be used.

The default colour palette goes from low expression in blue to high expression in red, which is a good alternative to the traditional red/green heatmaps which are not suitable for those with forms of colour-blindness.

```{r}
# pheatmap is a specialised package to make heatmaps
library(pheatmap)
top_genes <- dplyr::slice(results_annotated, 1:10) %>% pull(row)
vsd <- vst(dds)

# top_genes is a vector containing ENSEMBL names of the genes we want to see in the heatmap

pheatmap(assay(vsd)[top_genes,])
```

The heatmap is more informative if we add colours underneath the sample dendrogram to indicate which sample group each sample belongs to. This we can do by creating a data frame containing metadata for each of the samples in our dataset. With the `DESeq2` workflow we have already created such a data frame. We have to make sure the the rownames of the data frame are the same as the column names of the counts matrix.

```{r}
sampleInfo <- as.data.frame(colData(dds)[,c("condition","Treated")])

pheatmap(assay(vsd)[top_genes,],
         annotation_col = sampleInfo,
         scale="row")
```

Any plot we create in RStudio can be saved as a png or pdf file. We use the `png` or `pdf` function to create a file for the plot to be saved into and run the rest of the code as normal. The plot does not get displayed in RStudio, but printed to the specified file.

```{r}
png("heatmap_top10_genes.png",width=800,height=800)
pheatmap(assay(vsd)[top_genes,],
         annotation_col = sampleInfo)
# dev.off()
```

There are many arguments to explore in `pheatmap`. For example, we might want to use a specific order to the rows and columns rather than using clustering. A useful option is to specific our own labels for the rows (genes). The default is to use the rownames of the count matrix. In our cases these are Ensembl IDs and not easy to interpret.

```{r}
N <- 10
gene_labels <- dplyr::slice(results_annotated, 1:N) %>% pull(SYMBOL)

pheatmap(assay(vsd)[top_genes,],
         annotation_col = sampleInfo,
         labels_row = gene_labels,
         scale="row")
```

Given the nature of how the genes were selected for the heatmap, we shouldn't be surprised by the good separation that it demonstrates.

# Exercise

::: exercise
-   Produce a heatmap using the top 30 genes with the most extreme *log2 Fold-Change*
    -   HINT: The `abs` function can be used to convert all negative values to positive.
-   Label the heatmap with the gene `SYMBOL` of the genes
-   Is this heatmap as effective as separating the samples into groups?

```{r eval=FALSE}




```
:::


# The volcano plot

The last visualisation we will cover in this section is the *volcano plot* which is another way of looking at all your results. Similar to the MA plot, it shows the `log2FoldChange` on the x-axis and the statistical significance is shown so that the most significant genes are the highest on the y-axis.

It's perfectly possible to make this plot using standard `ggplot2` commands, but the package `EnhancedVolcano` does a really good job out of the box. If you don't have `EnhancedVolcano` installed you can use the following code:-

```{r eval=FALSE}
if(!require(BiocManager)) install.packages("BiocManager")
if(!require(EnhancedVolcano)) BiocManager::install("EnhancedVolcano")

```


`EnhancedVolcano` is useful as it will automatically label the names of the most significant genes and apply a colour scheme.

```{r message=FALSE, warning=FALSE, fig.width=10, fig.height=8}
library(EnhancedVolcano)

EnhancedVolcano(results_annotated, x = "log2FoldChange", 
                y = "padj", 
                lab = results_annotated$SYMBOL, 
                title = "TGF vs CTRL",
                subtitle = "")
```
This is quite a nice result using the defaults. As the function is using `ggplot2` under the hood it can be saved in the same ways as ordinary `ggplot2` figures.


```{r}
ggsave("TGF_vs_CTR_volcano.png")
```
Rather than labeling all the genes, we can just highlight some of interest

```{r fig.width=10, fig.height=8}
EnhancedVolcano(results_annotated, x = "log2FoldChange", 
                y = "padj", 
                lab = results_annotated$SYMBOL, 
                title = "TGF vs CTRL",
                selectLab = genes_of_interest,
                drawConnectors = TRUE,
                FCcutoff = 0.5,
                pCutoff = 0.05,
                subtitle  = "Selected ECM Genes")
```


## Exporting normalized counts

The `DESeq` workflow applies *median of ratios normalization* that accounts for differences in sequencing depth between samples. The user does not usually need to run this step. However, if you want a matrix of counts for some application outside of Bioconductor the values can be extracted from the `dds` object.

```{r}
dds <- estimateSizeFactors(dds) 
countMatrix <-counts(dds, normalized=TRUE) 
head(countMatrix)
write.csv(countMatrix,file="normalized_counts.csv")
```


Let's wrap-up for now and continue our exploration of the differential expression in the next section. If you want to find out more about the `DESeq` workflow then read on.

# Full DESeq workflow {#full-deseq-workflow}

The median of ratios normalisation method is employed in `DESeq2` to account for *sequencing depth* and *RNA composition*. Let's go through a short worked example (courtesy of [https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html](here)) to explain the process.

```{r}
## create a small example matrix of "counts"
test_data <- matrix(c(1489,22,793,76,521,906,13,410,42,1196),nrow=5)
rownames(test_data) <- c("EF2A","ABCD1","MEFV","BAG1","MOV10")
colnames(test_data) <- c("SampleA","SampleB")
test_data
```

Firstly, an "average" or reference sample is created that represents the counts on a typical sample in the dataset. The *geometric mean* is used rather than the *arithmetic* mean. In other words the individual counts are multiplied rather than summed and the measure should be more robust to outliers.

```{r}
psuedo_ref <- sqrt(rowProds(test_data))
psuedo_ref
```

A ratios of sample to "psuedo reference" are then calculated for each gene. We are assuming that most genes are not changing dramatically, so this ratio should be somewhere around 1.

```{r}
test_data/psuedo_ref
```

`DESeq2` defines size factors as being the *median* of these ratios for each sample (median is used so any outlier genes will not affect the normalisation).

```{r}
norm_factors <- colMedians(test_data/psuedo_ref)
norm_factors
```

Individual samples can then normalised by dividing the count for each gene by the corresponding normalization factor.

```{r}
test_data[,1] / norm_factors[1]
```

and for the second sample...

```{r}
test_data[,2] / norm_factors[2]

```

The size factors for each sample in our dataset can be calculated using the `estimateSizeFactorsForMatrix` function.

```{r}
sf <- estimateSizeFactorsForMatrix(assay(dds))
sf
```

The estimation of these factors can also take gene-lengths into account, and this is implemented in the `estimateSizeFactors` function. Extra normalization factor data is added to the `dds` object.

```{r eval=FALSE}
dds <- estimateSizeFactors(dds)
dds
```

In preparation for differential expression DESeq2 also need a reliable estimate of the variability of each gene; which it calls *dispersion*.

```{r eval=FALSE}
dds <- estimateDispersions(dds)
dds

```

A statistical test can then be applied. As the data are count-based and not normally-distributed a t-test would not be appropriate. Most tests are based on a *Poisson* or *negative-binomial* distribution; negative binomial in the case of `DESeq2`. Although you might not be familiar with the negative binomial, the results should be in a familiar form with fold-changes and p-values for each gene.

```{r eval=FALSE}
dds <- nbinomWaldTest(dds)
```

It may seem like there is a lot to remember, but fortunately there is one convenient function that will apply the three steps (`DESeq`). The messages printed serve as reminders of the steps included.
