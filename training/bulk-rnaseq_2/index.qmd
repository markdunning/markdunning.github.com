---
title: "Introduction to RNA-Seq - Part 2"
author: Mark Dunning
date: today
theme: darkly
image: "/files/training/bulk_rnaseq/part2_preview.png"
---

# Overview

Performing differential expression on Bulk RNA-seq data using DESeq2

## Quick Start

```{r eval=FALSE}
source("https://raw.githubusercontent.com/markdunning/markdunning.github.com/refs/heads/master/files/training/bulk_rnaseq/install_bioc_packages.R")
```

```{r eval=FALSE}
dir.create("Robjects/",showWarnings = FALSE)
download.file("https://github.com/markdunning/markdunning.github.com/raw/refs/heads/master/files/training/bulk_rnaseq/dds.rds",destfile = "Robjects/dds.rds")
```

# Differential expression with `DESeq2`

Now that we are happy that we have normalised the data and that the quality looks good, we can proceed to test for differentially expressed genes. There are a number of packages to analyse RNA-Seq data. Most people use `DESeq2` or `edgeR`. We will use `DESeq2` for the rest of this practical.

## Recap of pre-processing

The previous section walked-through the pre-processing and transformation of the count data. Here, for completeness, we list the minimal steps required to process the data prior to differential expression analysis.

Note that although we spent some time looking at the quality of our data , these steps are not required prior to performing differential expression so are not shown here. Remember, `DESeq2` [requires raw counts](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#why-un-normalized-counts) so the `vst` transformation is not shown as part of this basic protocol.

```{r eval=FALSE}
library(DESeq2)

count_file <- "raw_counts/raw_counts_matrix.tsv"
counts <- read.delim(count_file)

## Step needed for this data to tidy the column names
colnames(counts)[-1] <- stringr::str_remove_all(colnames(counts)[-1], "X")

sampleinfo_corrected <- read.delim("meta_data/sampleInfo_corrected.txt")
dds <- DESeqDataSetFromMatrix(counts, 
                                colData = sampleinfo_corrected,
                                design = ~condition, tidy=TRUE)

saveRDS(dds, file="Robjects/dds.rds")
```

We will be using these raw counts throughout the workshop and transforming them using methods in the `DESeq2` package. If you want to know about alternative methods for count normalisation they are covered on [this page](https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html).

# The DESeq workflow in brief

```{r echo=FALSE, message=FALSE}
library(DESeq2)
dds <- readRDS("Robjects/dds.rds")
```

We have previously defined the test condition using the `design` argument when we created the object. This can be checked using the `design` function.

Typically we decide the design for the analysis when we create the DESeq2 objects, but it can be modified prior to the differential expression analysis. The design tells `DESeq2` which sample groups to compare in the differential analysis. The name specified must correspond to a column in the sample information.

```{r}
colData(dds)
```

The current design can be retrieved using the `design` function.

```{r}
design(dds)
```

The counts that we have obtained via sequencing are subject to random sources of variation. The purpose of differential expression is to determine if potential sources of biological variation (e.g. counts observed from different sample groups) are greater than random noise.

The `DESeq` function runs a couple of processing steps automatically to adjust for different library size and gene-wise variability, which you can read about in the [DESeq2 vignette](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#the-deseq2-model) and run some example code at the [end of this session](#full-deseq-workflow).

```{r}
de_condition <- DESeq(dds)
de_condition
```

The results of the analysis are not immediately accessible, but can be obtained using the `results` function. 

```{r}
results(de_condition)
```

Each row is a particular gene measured in the study (i.e. all genes in the organism being studied) and each column reports some aspect of the differential expression analysis for that gene. The values that I pay most attention are highlighted in **bold**.

| Column Name | Description | Importance |
|------------------------|------------------------------|------------------------|
| **baseMean** | The average of normalized count values (size-factor corrected) across all samples in the comparison. | Measures the average expression magnitude of the gene and useful for basic filtering |
| **log2FoldChange** | The estimated log base 2 fold change between the two groups being contrasted (e.g., Treatment / Control). | The primary measure of the effect size or magnitude of the difference. |
| lfcSE | The standard error estimate for the $\text{log}_2\text{FoldChange}$. | Measures the precision of the $\text{log}_2\text{FC}$ estimate. Smaller values indicate higher reliability. |
| stat | The Wald test statistic (calculated as $\text{log}_2\text{FC} / \text{lfcSE}$) | The statistical value used to test the null hypothesis (that the $\text{log}_2\text{FC}$ is zero) |
| pvalue | The $p$-value derived from the Wald test statistic. | The unadjusted probability of observing the effect by chance. Do not use this for filtering. |
| **padj** | The Benjamini-Hochberg adjusted $p$-value (False Discovery Rate, FDR).CRITICAL for significance. This corrects for multiple testing | CRITICAL for statistical significance. This corrects for multiple testing. Genes are considered differentially expressed if this value is below your threshold (e.g., 0.05). |


Note that **all genes** are reported. At this stage the gene identifiers are not very informative, something we will fix shortly. Furthermore, the `results` function displays results in a format which is not compatible with standard data manipulation tools (i.e. `tidyverse`), so we will have to convert.


# Processing the DE results using tidyverse

The output can be converted into a data frame and manipulated in the usual manner using the `tidy = TRUE` argument. It is recommended to use `dplyr` to manipulate the data frames with the standard set of operations detailed on the [dplyr cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

-   `select` to pick which columns to display
-   `filter` to restrict the rows
-   `mutate` to add new variables to the data frame
-   `arrange` to order the data frame according to values of a column

The `%>%` symbol refers to the [piping operation](https://sbc.shef.ac.uk/r-online/part2.nb.html#%E2%80%9CPiping%E2%80%9D) in R, which is a way of chaining operations together.

```{r warning=FALSE, message=FALSE}
library(dplyr)
 results(de_condition, tidy=TRUE) %>% 
   slice_head(n=10)
```

::: callout-note
Although, the "tidy" output is more useful for downstream analysis, I personally like the output generated by the `results` function without `tidy=TRUE` as it displays the contrast being tested (in this case `TGF vs CTR`). This is a good way of checking that you are comparing the groups that you expect.
:::

We can sort the rows by adjusted p-value and then print the first 10 rows.

```{r}
results(de_condition,tidy=TRUE) %>%
  arrange(padj) %>%  
  slice_head(n=10)
```

Or we can sort the rows and then write the resulting data frame to a file.

```{r}
dir.create("de_analysis",showWarnings = FALSE)
 results(de_condition,tidy=TRUE) %>%
  arrange(padj) %>% 
   readr::write_csv("de_analysis/condition_TGF_vs_CTR_DESeq_all.csv")
```

Filtering to the differentially-expressed genes can be achieved using the `filter` function from `dplyr` with some cut-off on the adjusted p-value.

```{r}
 results(de_condition,tidy=TRUE) %>%
  filter(padj < 0.05) %>% 
  readr::write_csv("de_analysis/condition_TGF_vs_CTR_DESeq_sig.csv")
```

It is also a good idea to save the results object itself so we can re-use later.

```{r}
saveRDS(de_condition, file="Robjects/de_condition.rds")
```

We can discover how many differentially-expressed genes (at a particular p-value cut-off) using the `count` function

```{r}
results(de_condition,tidy=TRUE) %>%
  dplyr::count(padj < 0.05)
```

Another overview of the results is to use the `plotMA` function. Each point on this plot represents and individual gene with the x- and y-axes being the overall expression level and magnitude of difference respectively. Significant genes are automatically highlighted. The fanning effect at low expression levels is often seen due to high relative fold-change at low expression levels.

```{r}
plotMA(de_condition)
```

It is also instructive to perform a "sanity" check and plot the sample-level counts for genes with high significance. This could highlight any other technical factors that we are not currently taking into account. The plot is not particularly attractive, but is a good quick diagnostic.

```{r}

top_up <- results(de_condition, tidy = TRUE) %>% 
  filter(log2FoldChange > 0) %>% 
  slice_min(padj) %>% 
  pull(row)
plotCounts(dds,top_up,intgroup = "condition")
```

```{r}
top_down <- results(de_condition, tidy = TRUE) %>% 
  filter(log2FoldChange < 0) %>% 
  slice_min(padj) %>% 
  pull(row)

plotCounts(dds,top_down,intgroup = "condition")
```

::: callout-note
If your study involves knocking-out a particular gene, or you have some positive controls that are known in advance, it would be a good idea to visualise their expression level with `plotCounts`.
:::

# Changing the direction of the contrast, or the groups being compared

In this initial analysis `DESeq2` has automatically decided which member of our sample groups to use as our baseline (`CTR` in this case). If the log2 fold changes has a positive value this means higher expression in `TGF` sample. We can alter this by changing the `contrast` argument in the `results` function

```{r eval=FALSE}
## This should give the same as the table above
results(de_condition, contrast=c("condition","TGF","CTR"))
## Changing the direction of the contrast
results(de_condition, contrast=c("condition","CTR","TGF"))
```

If we want to perform differential expression analysis on the `condition` variable then there are various contrasts that can be made; `IR` vs `CTR`, `TGF` vs `CTR` etc. When the `results` function is run with no `contrast` argument specified, the table that is displayed is for the contrast `TGF vs CTR`. The `resultsNames` function can tell us which other contrasts we can access.


## Exercise

-   Re-run the analysis to find differentially-expressed genes between the `IR` treated samples and `CTR`
-   Write a csv file that contains results for the genes that have an *adjusted* p-value less than 0.05 and a log2 fold change more than 1, or less than -1 in the contrast of TGF vs CTRL.
-   Use the `plotCounts` function to visually-inspect the most statistically-significant gene identified


# More complex designs

The examples we have used so far have performed a differential expression analysis using a named column in the `colData` object. The `DESeq2` package is capable of performing more complex analyses that can take multiple factors into consideration at the same time; so-called "multi-factor designs"

-   [Multi-factor designs in DESeq2](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#multi-factor-designs)

The use of such a design could be motivated by discovering sources of technical variation in our data that might obscure the biological differences we would like to compare. e.g.

![](images/batch_effect.png)

In the example image above the main source of variation is the batch in which the samples were sequenced. A multi-factor analysis to compare the various conditions, but "correct" for differences in batch, would be as follows.

```{r eval=FALSE}
### Don't run this. It's just a code example
design(MY_DATA) <- ~ batch + condition
```

Likewise, if we have different treatments applied to difference cell-lines, but the main source of variation is the cell line the following could be used.

```{r eval=FALSE}
### Don't run this. It's just a code example
design(MY_DATA) <- ~cell_line + treatment
```

# Adding annotation to the DESeq2 results

We would love to share these results with our collaborators, or search for our favourite gene in the results. However, the results are not very useful in there current form as each row is named according to an *Ensembl* identifier. Whilst gene symbols are problematic and can change over time, they are the names that are most recognisable and make the results easier to navigate.

There are a number of ways to add annotation, but we will demonstrate how to do this using the *org.Hs.eg.db* package. This package is one of several *organism-level* packages in Bioconductor that are re-built every 6 months. These packages are listed on the [annotation section](http://bioconductor.org/packages/release/BiocViews.html#___AnnotationData) of the Bioconductor, and are installed in the same way as regular Bioconductor packages. An alternative approach is to use `biomaRt`, an interface to the [BioMart](http://www.biomart.org/) resource. BioMart is much more comprehensive, but the organism packages do not require online access once downloaded.

```{r eval=FALSE}
### Only execute when you need to install the package
install.packages("BiocManager")
BiocManager::install("org.Hs.eg.db")
# For Human
BiocManager::install("org.Hs.eg.db")
```

The packages are larger in size that Bioconductor software packages, but essentially they are databases that can be used to make *offline* queries. An alternatve (`biomaRt`) that connects to the ensembl [biomart](https://www.ensembl.org/info/data/biomart/index.html) resource will be discussed later.

```{r message=FALSE}
library(org.Hs.eg.db)
```

First we need to decide what information we want. In order to see what we can extract we can run the `columns` function on the annotation database.

```{r}
columns(org.Hs.eg.db)
```

We are going to filter the database by a key or set of keys in order to extract the information we want. Valid names for the key can be retrieved with the `keytypes` function.

```{r}
keytypes(org.Hs.eg.db)
```

We should see `ENSEMBL`, which is the type of key we are going to use in this case. If we are unsure what values are acceptable for the key, we can check what keys are valid with `keys`

```{r}
keys(org.Hs.eg.db, keytype="ENSEMBL")[1:10]
```

For the top gene in our analysis the call to the function would be:-

```{r eval=FALSE}
select(org.Hs.eg.db, keys=top_up,
       keytype = "ENSEMBL",columns=c("SYMBOL","GENENAME")
)
```

Unfortunately, the authors of `dplyr` and `AnnotationDbi` have both decided to use the name `select` in their packages. To avoid confusion and errors, the following code is sometimes used:-

```{r}
AnnotationDbi::select(org.Hs.eg.db, keys=top_up,keytype = "ENSEMBL",columns=c("SYMBOL","GENENAME"))
```

To annotate our results, we definitely want gene symbols and perhaps the full gene name. Let's build up our annotation information into a new data frame using the `select` function.

```{r}
anno <- AnnotationDbi::select(org.Hs.eg.db,keys=rownames(dds),
              columns=c("SYMBOL","GENENAME"),
              keytype="ENSEMBL")
# Have a look at the annotation
head(anno)
```

However, we have a problem that the resulting data frame has more rows than our results table. This is due to the *one-to-many* relationships that often occur when mapping between various identifiers.

```{r}
dim(anno)
dim(dds)
```

Such duplicated entries can be identified using the `duplicated` function. Fortunately, there are not too many so hopefully we won't lose too much information if we discard the entries that are duplicated. The first occurrence of the duplicated ID will still be included in the table.

```{r}
anno <- AnnotationDbi::select(org.Hs.eg.db,keys=rownames(dds),
            columns=c("ENSEMBL","SYMBOL","GENENAME","ENTREZID"),
            keytype="ENSEMBL") %>% 
filter(!duplicated(ENSEMBL))
dim(anno)
```

We can bind in the annotation information to the `results` data frame.

```{r}
results_annotated <- results(de_condition,tidy=TRUE) %>% 
  left_join(anno, by=c("row"="ENSEMBL"))

head(results_annotated)
```

We can save the results table using the `write.csv` function, which writes the results out to a csv file that you can open in excel.

```{r}
write.csv(results_annotated,file="de_analysis/condition_TGF_vs_CTR_DESeq_annotated.csv",row.names=FALSE)
```

## Exercise

-   The publication gives examples of `COL1A1`, `COL1A2` and `COL3A1` as genes that are *up-regulated* in TGF-treated samples vs controls (Figure 6C). Use your data to verify this by
    i)  extracting their p-values
    ii) plotting the counts for these genes


## The volcano plot

```{r}
library(EnhancedVolcano)

EnhancedVolcano(results_annotated, x = "log2FoldChange", y = "padj", lab = results_annotated$SYMBOL)

```



### Exporting normalized counts

The `DESeq` workflow applies *median of ratios normalization* that accounts for differences in sequencing depth between samples. The user does not usually need to run this step. However, if you want a matrix of counts for some application outside of Bioconductor the values can be extracted from the `dds` object.

```{r}
dds <- estimateSizeFactors(dds) 
countMatrix <-counts(dds, normalized=TRUE) 
head(countMatrix)
write.csv(countMatrix,file="normalized_counts.csv")
```

# Full DESeq workflow

The median of ratios normalisation method is employed in DESeq2 to account for *sequencing depth* and *RNA composition*. Let's go through a short worked example (courtesy of [https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html](here)) to explain the process.

```{r}
## create a small example matrix of "counts"
test_data <- matrix(c(1489,22,793,76,521,906,13,410,42,1196),nrow=5)
rownames(test_data) <- c("EF2A","ABCD1","MEFV","BAG1","MOV10")
colnames(test_data) <- c("SampleA","SampleB")
test_data
```

Firstly, an "average" or reference sample is created that represents the counts on a typical sample in the dataset. The *geometric mean* is used rather than the *arithmetic* mean. In other words the individual counts are multiplied rather than summed and the measure should be more robust to outliers.

```{r}
psuedo_ref <- sqrt(rowProds(test_data))
psuedo_ref
```

A ratios of sample to "psuedo reference" are then calculated for each gene. We are assuming that most genes are not changing dramatically, so this ratio should be somewhere around 1.

```{r}
test_data/psuedo_ref
```

`DESeq2` defines size factors as being the *median* of these ratios for each sample (median is used so any outlier genes will not affect the normalisation).

```{r}
norm_factors <- colMedians(test_data/psuedo_ref)
norm_factors
```

Individual samples can then normalised by dividing the count for each gene by the corresponding normalization factor.

```{r}
test_data[,1] / norm_factors[1]
```

and for the second sample...

```{r}
test_data[,2] / norm_factors[2]

```

The size factors for each sample in our dataset can be calculated using the `estimateSizeFactorsForMatrix` function.

```{r}
sf <- estimateSizeFactorsForMatrix(assay(dds))
sf
```

The estimation of these factors can also take gene-lengths into account, and this is implemented in the `estimateSizeFactors` function. Extra normalization factor data is added to the `dds` object.

```{r eval=FALSE}
dds <- estimateSizeFactors(dds)
dds
```

In preparation for differential expression DESeq2 also need a reliable estimate of the variability of each gene; which it calls *dispersion*.

```{r eval=FALSE}
dds <- estimateDispersions(dds)
dds

```

A statistical test can then be applied. As the data are count-based and not normally-distributed a t-test would not be appropriate. Most tests are based on a *Poisson* or *negative-binomial* distribution; negative binomial in the case of `DESeq2`. Although you might not be familiar with the negative binomial, the results should be in a familiar form with fold-changes and p-values for each gene.

```{r eval=FALSE}
dds <- nbinomWaldTest(dds)
```

It may seem like there is a lot to remember, but fortunately there is one convenient function that will apply the three steps (`DESeq`). The messages printed serve as reminders of the steps included.
